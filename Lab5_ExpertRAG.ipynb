{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c151ca65",
   "metadata": {},
   "source": [
    "# Lab 5 — ExpertRAG End‑to‑End Demo\n",
    "Combine **MoE‑style expert routing**, **retrieval‑augmented generation**, and **guardrails** into one pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62128bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install langchain sentence-transformers faiss-cpu openai guardrails-ai ragas matplotlib tqdm\n",
    "import warnings, os; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1767151",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "| Variable | Purpose |\n",
    "|----------|---------|\n",
    "| `OPENAI_API_KEY` | LLM calls via LangChain/OpenAI |\n",
    "| `PINECONE_API_KEY`, `PINECONE_ENV` | (Optional) Use Pinecone instead of local FAISS |\n",
    "\n",
    "Set locally:\n",
    "```bash\n",
    "export OPENAI_API_KEY=\"sk-...\"\n",
    "```\n",
    "Or in Colab:\n",
    "```python\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY']='sk-...'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6209e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, openai\n",
    "if not os.getenv('OPENAI_API_KEY'):\n",
    "    raise ValueError('OPENAI_API_KEY missing')\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "print('OpenAI key loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0976ea06",
   "metadata": {},
   "source": [
    "## 1. Prepare Domain Corpora\n",
    "For demo purposes we’ll create two tiny domain‑specific corpora (medical & finance). Replace with your own documents in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae60ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_docs = [\n",
    "    'Hypertension is a chronic medical condition in which the blood pressure in the arteries is persistently elevated.',\n",
    "    'The normal resting heart rate for adults ranges from 60 to 100 beats per minute.'\n",
    "]\n",
    "finance_docs = [\n",
    "    'The S&P 500 is a stock market index tracking the stock performance of 500 large companies listed on exchanges in the United States.',\n",
    "    'Compound interest is the addition of interest to the principal sum of a loan or deposit.'\n",
    "]\n",
    "print('Loaded corpora: medical', len(medical_docs), '| finance', len(finance_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c555cced",
   "metadata": {},
   "source": [
    "## 2. Embed & Index with FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce51abdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "embed = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "store_med = FAISS.from_texts(medical_docs, embed)\n",
    "store_fin = FAISS.from_texts(finance_docs, embed)\n",
    "retrievers = {'MEDICAL': store_med.as_retriever(search_kwargs={'k':3}),\n",
    "             'FINANCE': store_fin.as_retriever(search_kwargs={'k':3})}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb58ac3d",
   "metadata": {},
   "source": [
    "## 3. Define Experts & Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c495d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMRouterChain\n",
    "from langchain.output_parsers import RouterOutputParser\n",
    "\n",
    "llm_expert = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "\n",
    "prompt_med = ChatPromptTemplate.from_messages([\n",
    "    ('system','You are a medical expert. Answer medically.'),\n",
    "    ('user','{query}')\n",
    "])\n",
    "prompt_fin = ChatPromptTemplate.from_messages([\n",
    "    ('system','You are a finance expert. Answer with financial knowledge.'),\n",
    "    ('user','{query}')\n",
    "])\n",
    "\n",
    "router_prompt = (\n",
    "    'Classify the user question into one of the following domains: MEDICAL, FINANCE.\\n'\n",
    "    'If unsure choose FINANCE. Respond with the class name only.'\n",
    ")\n",
    "router = LLMRouterChain.from_llm(\n",
    "    llm=ChatOpenAI(model='gpt-3.5-turbo', temperature=0),\n",
    "    prompt=router_prompt,\n",
    "    output_parser=RouterOutputParser(choices=['MEDICAL','FINANCE'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5024126f",
   "metadata": {},
   "source": [
    "### 3.1 Conditional Retrieval Decision\n",
    "The router also decides whether to `RETRIEVE` based on complexity keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d97777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def need_retrieval(query):\n",
    "    trigger = any(k in query.lower() for k in ['define','explain','what is','when','history'])\n",
    "    return trigger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b21ad3f",
   "metadata": {},
   "source": [
    "## 4. Guardrails\n",
    "Use a toxicity validator and a simple grounding checker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf5980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from guardrails import Guard, OnFailAction\n",
    "from guardrails.hub import ToxicLanguage\n",
    "\n",
    "guard_toxic = Guard().use(ToxicLanguage(threshold=0.7, validation_method='sentence', on_fail=OnFailAction.EXCEPTION))\n",
    "\n",
    "def grounding_checker(answer, retrieved):\n",
    "    missing = []\n",
    "    for sent in answer.split('. '):\n",
    "        if sent and not any(sent.strip().lower() in d.lower() for d in retrieved):\n",
    "            missing.append(sent)\n",
    "    return missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f536e9",
   "metadata": {},
   "source": [
    "## 5. ExpertRAG Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d24d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expert_rag(query):\n",
    "    domain = router.run(query)\n",
    "    retrieve = need_retrieval(query)\n",
    "    context_chunks = []\n",
    "    if retrieve:\n",
    "        context_docs = retrievers[domain].get_relevant_documents(query)\n",
    "        context_chunks = [d.page_content for d in context_docs]\n",
    "        context = '\\n'.join(context_chunks)\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            ('system', f'You are a {domain.lower()} expert. Use the provided CONTEXT to answer.\\nCONTEXT:\\n{context}'),\n",
    "            ('user', query)\n",
    "        ])\n",
    "    else:\n",
    "        prompt = prompt_med if domain=='MEDICAL' else prompt_fin\n",
    "    answer = llm_expert.invoke(prompt.format(query=query))\n",
    "    # Guardrails\n",
    "    guard_toxic.validate(answer)\n",
    "    if retrieve:\n",
    "        missing = grounding_checker(answer, context_chunks)\n",
    "        if missing:\n",
    "            raise ValueError('Answer not fully grounded:', missing)\n",
    "    return domain, retrieve, answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411387ec",
   "metadata": {},
   "source": [
    "## 6. Demo Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ea43bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    'What is hypertension?',\n",
    "    'Explain compound interest.',\n",
    "    'Give me health advice about heart rate.',\n",
    "    'Define EBITDA.'\n",
    "]\n",
    "for q in queries:\n",
    "    d, r, a = expert_rag(q)\n",
    "    print(f'[{d} | retrieve={r}] {q}\\n{a}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b066938",
   "metadata": {},
   "source": [
    "## ✏️ Exercises (Lab 5)\n",
    "1. **Add a Tech Expert** – create a technology corpus, index it, extend router choices, and test.\n",
    "2. **Retrieval Decision Tuning** – swap `need_retrieval` heuristic with an LLM‑based confidence score.\n",
    "3. **Expert‑Level Guardrails** – apply a stricter validator only for medical answers (e.g., block medical advice).\n",
    "4. **Latency & Cost Measurement** – profile ExpertRAG vs dense GPT‑4 answer for 20 mixed queries.\n",
    "5. **Grounding Metric** – integrate `ragas` faithfulness metric to auto‑grade each ExpertRAG response."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
